task_name: train
tags:
- CIFAR10
- DDPM
train: true
test: true
compile: false
ckpt_path: null
seed: 12345
data:
  _target_: src.data.cifar10_datamodule.CIFAR10DataModule
  data_dir: ${paths.data_dir}
  batch_size: 128
  train_val_test_split:
  - 45000
  - 5000
  - 10000
  num_workers: 32
  pin_memory: true
  persistent_workers: true
model:
  _target_: src.models.ddpm_cfg_module.DDPM_CFG_Module
  cfg_scale: 3
  label_drop_rate: 0.1
  num_classes: 10
  img_size: 32
  noise_steps: 1000
  in_channels: 3
  diffusion:
    _target_: src.models.components.diffusion.Diffusion
    noise_steps: 1000
    beta_start: 0.0001
    beta_end: 0.02
    img_size: 32
    num_classes: 10
    in_channels: 3
    out_channels: 3
    noise_schedule: linear
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.001
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.1
    patience: 10
  net:
    _target_: src.models.components.ddpm_cfg_unet_2d.ConditionedUnet
    in_channels: 3
    out_channels: 3
    block_count: 3
    num_classes: 10
    init_depth: 64
    depth_multiplier: 2
    time_dim: 256
    remove_deep_conv: false
callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: epoch_{epoch:03d}
    monitor: val/loss
    verbose: false
    save_last: true
    save_top_k: 1
    mode: min
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val/loss
    min_delta: 0.0
    patience: 100
    verbose: false
    mode: min
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: null
  model_summary:
    _target_: lightning.pytorch.callbacks.RichModelSummary
    max_depth: -1
  rich_progress_bar:
    _target_: lightning.pytorch.callbacks.RichProgressBar
logger:
  wandb:
    _target_: lightning.pytorch.loggers.wandb.WandbLogger
    save_dir: ${paths.output_dir}
    offline: false
    id: null
    anonymous: null
    project: CIFAR10-DDPM
    log_model: false
    prefix: ''
    group: ''
    tags:
    - DDPM
    job_type: ''
    name: DDPM
trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${paths.output_dir}
  min_epochs: 10
  max_epochs: 2000
  accelerator: gpu
  devices:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  check_val_every_n_epoch: 50
  deterministic: false
  gradient_clip_val: 1
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: ${paths.root_dir}/data/
  log_dir: ${paths.root_dir}/logs/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
extras:
  ignore_warnings: true
  enforce_tags: true
  print_config: true
diffusion:
  noise_steps: 1000
  img_size: 32
  num_classes: 10
  in_channels: 3
  out_channels: 3
  noise_schedule: linear
cfg_scale: 3
label_drop_rate: 0.1
num_classes: 10
img_size: 32
noise_steps: 1000
in_channels: 3
